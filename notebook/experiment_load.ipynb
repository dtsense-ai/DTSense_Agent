{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4627af87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4393309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3b/q41jplbn65g195twm96s5qjc0000gn/T/ipykernel_66953/642717045.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  _embeddings_instance = HuggingFaceEmbeddings(model_name=model_name)\n",
      "/Users/alvinrindra/Documents/dtsense-rag/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Singleton holder for the embeddings instance\n",
    "_embeddings_instance: HuggingFaceEmbeddings | None = None\n",
    "\n",
    "def get_hf_embeddings(\n",
    "    model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ") -> HuggingFaceEmbeddings:\n",
    "    \"\"\"\n",
    "    Return a cached HuggingFaceEmbeddings instance for `model_name`.\n",
    "    On first call it will download (if needed), later calls reuse the same object.\n",
    "    \"\"\"\n",
    "    global _embeddings_instance\n",
    "    if _embeddings_instance is None:\n",
    "        # This will download the model into your HF cache dir if not already present\n",
    "        _embeddings_instance = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return _embeddings_instance\n",
    "\n",
    "\n",
    "model = get_hf_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451b056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data  from pdf file\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data, # <- directory file\n",
    "                             glob=\"*.pdf\", # <- all pdf on folder\n",
    "                             loader_cls=PyPDFLoader # <- function implement to load pdf\n",
    "                             )\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "#function chucking documents\n",
    "def text_splitter(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks   = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ede276",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = load_pdf('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88f0467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cef7014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5860"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunk = text_splitter(document)\n",
    "len(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91a412b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5798f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pcsk_6sNBQJ_L3HnKrjUCYGzYbEXCFxXGTicumokQvpNEY85zWXWQCPypmS9vRvAnWc5z4fDWSv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64708001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = 'medicalbot'\n",
    "\n",
    "\n",
    "# pc.create_index(\n",
    "#     name=index_name,\n",
    "#     dimension=384,\n",
    "#     metric='cosine',\n",
    "#     spec=ServerlessSpec(\n",
    "#         cloud='aws',\n",
    "#         region=\"us-east-1\"\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d87c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"medical-index\"\n",
    "\n",
    "# create index (kalau belum ada)\n",
    "if index_name not in [i[\"name\"] for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # sesuaikan embedding\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d48ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# import pinecone\n",
    "# from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "# # pinecone.init(\n",
    "# #     api_key=PINECONE_API_KEY,\n",
    "# #     environment=\"us-east-1\"\n",
    "# # )\n",
    "\n",
    "# docsearch = Pinecone.from_documents(\n",
    "#     documents=text_chunk,\n",
    "#     index_name=index_name,\n",
    "#     embedding=model\n",
    "# )\n",
    "\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "\n",
    "# docsearch = PineconeVectorStore.from_documents(\n",
    "#     documents=text_chunk,\n",
    "#     embedding=model,\n",
    "#     index_name=\"medical-index\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30d3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load existing index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "699deb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting retiever\n",
    "rertriever = docsearch.as_retriever(search_type='similarity', search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41e9fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 39, 'source': '../Data/Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(metadata={'page': 38, 'source': '../Data/Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(metadata={'page': 37, 'source': '../Data/Medical_book.pdf'}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "rertriever.invoke(\"What is acne ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df8a6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 39, 'total_tokens': 64, 'completion_time': 0.040050444, 'completion_tokens_details': None, 'prompt_time': 0.004725686, 'prompt_tokens_details': None, 'queue_time': 0.092963407, 'total_time': 0.04477613}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'finish_reason': 'stop', 'logprobs': None}, id='run-62106366-de02-41f1-8ec0-fdbaad862470-0', usage_metadata={'input_tokens': 39, 'output_tokens': 25, 'total_tokens': 64})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')\n",
    "\n",
    "\n",
    "#define groq llm\n",
    "llm = ChatGroq(temperature=0.5,\n",
    "                groq_api_key=GROQ_API_KEY, \n",
    "                model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# import os\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-3-flash-preview\",\n",
    "#     temperature=0.5,\n",
    "#     google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "# )\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810145d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed2775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an asistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you dot't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\",\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51ade58",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(rertriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e44c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Doppler effect refers to the apparent change in frequency of sound wave echoes returning to a stationary source from a moving target. This change in frequency can be used to compute the object's speed, whether it's a car or blood in an artery. The Doppler effect holds true for all types of radiation, not just sound.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "        \"input\":\"What is definition for Doppler?\"\n",
    "    })\n",
    "\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec111588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know what machine learning is based on the provided context, as it doesn't mention machine learning. The context appears to be related to human memory, neurodegenerative diseases, and cancer treatments.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\n",
    "        \"input\":\"What is machine learning?\"\n",
    "    })\n",
    "\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eafab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
